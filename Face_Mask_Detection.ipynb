{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newuser\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import *\n",
    "from pyimagesearch.lenet import LeNet\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images(\"dataset\"))\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    image = load_img(imagePath, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "    test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newuser\\Anaconda3\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:306: UserWarning: MobileNet shape is undefined. Weights for input shape(224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LeNet.build(width=224, height=224, depth=3, classes=2)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "34/34 [==============================] - 1102s 32s/step - loss: 0.5917 - acc: 0.6857 - val_loss: 0.3274 - val_acc: 0.8804\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 1016s 30s/step - loss: 0.3848 - acc: 0.8168 - val_loss: 0.2128 - val_acc: 0.9203\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1004s 30s/step - loss: 0.2826 - acc: 0.8741 - val_loss: 0.1585 - val_acc: 0.9529\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1006s 30s/step - loss: 0.2281 - acc: 0.9170 - val_loss: 0.1182 - val_acc: 0.9674\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1007s 30s/step - loss: 0.1989 - acc: 0.9161 - val_loss: 0.0836 - val_acc: 0.9710\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1006s 30s/step - loss: 0.1826 - acc: 0.9281 - val_loss: 0.0735 - val_acc: 0.9710\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1237s 36s/step - loss: 0.1652 - acc: 0.9406 - val_loss: 0.0650 - val_acc: 0.9710\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1026s 30s/step - loss: 0.1277 - acc: 0.9510 - val_loss: 0.0839 - val_acc: 0.9819\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1120s 33s/step - loss: 0.1483 - acc: 0.9413 - val_loss: 0.0524 - val_acc: 0.9746\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1000s 29s/step - loss: 0.1493 - acc: 0.9406 - val_loss: 0.0490 - val_acc: 0.9855\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1018s 30s/step - loss: 0.1055 - acc: 0.9641 - val_loss: 0.0488 - val_acc: 0.9746\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1006s 30s/step - loss: 0.1340 - acc: 0.9461 - val_loss: 0.0508 - val_acc: 0.9891\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1016s 30s/step - loss: 0.1171 - acc: 0.9553 - val_loss: 0.0535 - val_acc: 0.9855\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1031s 30s/step - loss: 0.0953 - acc: 0.9660 - val_loss: 0.0600 - val_acc: 0.9855\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1005s 30s/step - loss: 0.0993 - acc: 0.9580 - val_loss: 0.0520 - val_acc: 0.9855\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1006s 30s/step - loss: 0.0888 - acc: 0.9697 - val_loss: 0.0597 - val_acc: 0.9855\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1006s 30s/step - loss: 0.0822 - acc: 0.9733 - val_loss: 0.0448 - val_acc: 0.9891\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1005s 30s/step - loss: 0.0813 - acc: 0.9752 - val_loss: 0.0504 - val_acc: 0.9855\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1007s 30s/step - loss: 0.1093 - acc: 0.9586 - val_loss: 0.0515 - val_acc: 0.9855\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1011s 30s/step - loss: 0.0742 - acc: 0.9774 - val_loss: 0.0523 - val_acc: 0.9855\n"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs = model.predict(testX, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.97      1.00      0.99       138\n",
      "without_mask       1.00      0.97      0.99       138\n",
      "\n",
      " avg / total       0.99      0.99      0.99       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "    target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"maskmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPaths = list(paths.list_images(\"jei\"))\n",
    "data = []\n",
    "labels = []\n",
    "for imgPath in imgPaths:\n",
    "    label = imgPath.split(os.path.sep)[-2]\n",
    "    image = load_img(imgPath, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mask, withoutMask) = model.predict(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2434639"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75653607"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withoutMask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
